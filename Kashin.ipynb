{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1o3QOgKViGO-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lamb(d, D):\n",
    "\n",
    "    return D / d\n",
    "\n",
    "def find_matrix_U(d, D):\n",
    "    \n",
    "    G = torch.normal(0, 1, [D, D])\n",
    "    Q, R = torch.qr(G)\n",
    "    \n",
    "    row_norms = torch.norm(Q, dim=1, keepdim=True)\n",
    "    Q_normalized = Q / row_norms                   # В какой момент нужно проводить нормализацию? \n",
    "    \n",
    "    U = Q_normalized[:d]\n",
    "\n",
    "    return U\n",
    "\n",
    "def find_params(D, U: torch.FloatTensor, X: torch.FloatTensor, eps=0.1):      \n",
    "    # X - array of n d-dimentional torch.FloatTensors; A - first condition set, B - second condition set\n",
    "\n",
    "    # delta = (1 / 5 ** 4) * ((1 - 1 / (lamb ** 0.5)) ** 2)\n",
    "    # eta = (3 / 4) + (1 / 4) * (1 / (lamb ** 0.5))\n",
    "    \n",
    "    npU = torch.Tensor.numpy(U)\n",
    "    npX = torch.Tensor.numpy(X)\n",
    "        \n",
    "    A_marked = [[x, np.argwhere(x == 0).shape[0]] for x in npX]\n",
    "    A_sorted = sorted(A_marked, key=lambda x: x[1])\n",
    "    \n",
    "    if A_sorted[-1][1] / D >= 1:\n",
    "        raise Exception(\"pu pu pu\")\n",
    "    delta = A_sorted[-1][1] / D + eps\n",
    "    while delta >= 1:\n",
    "        eps *= eps\n",
    "        delta = A_sorted[-1][1] / D + eps\n",
    "    \n",
    "    B_marked = [[x, np.linalg.norm(np.dot(npU, x)) / np.linalg.norm(x)] for x in npX]\n",
    "    B_sorted = sorted(B_marked, key=lambda x: x[1])\n",
    "\n",
    "    if B_sorted[-1][1] >= 1:\n",
    "        raise Exception(\"pu pu pu\")\n",
    "    eta = B_sorted[-1][1] + eps\n",
    "    while eta >= 1:\n",
    "        eps *= eps\n",
    "        eta = B_sorted[-1][1] + eps\n",
    "\n",
    "    return delta, eta\n",
    "\n",
    "def find_eta(D, U: torch.FloatTensor, X: torch.FloatTensor):\n",
    "\n",
    "    npU = torch.Tensor.numpy(U)\n",
    "    npX = torch.Tensor.numpy(X)\n",
    "\n",
    "    B_marked = [[x, np.linalg.norm(np.dot(npU, x)) / np.linalg.norm(x)] for x in npX]\n",
    "    B_sorted = sorted(B_marked, key=lambda x: x[1])\n",
    "\n",
    "    if B_sorted[-1][1] >= 1:\n",
    "        raise Exception(\"pu pu pu\")\n",
    "    eta = B_sorted[-1][1] + eps\n",
    "    while eta >= 1:\n",
    "        eps *= eps\n",
    "        eta = B_sorted[-1][1] + eps\n",
    "\n",
    "    return eta\n",
    "\n",
    "def hardcode_eta(lamb):\n",
    "    return (3 / 4) + (1 / 4) * (1 / (math.sqrt(lamb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "W9VbjpPkiMz6"
   },
   "outputs": [],
   "source": [
    "def gridsearch_all_a(X, lamb: int, r: int, delta, eta): \n",
    "    # A - array of n D-dimentional torch.FloatTensors a;\n",
    "    \n",
    "    A = torch.zeros(X.shape[0], D)   # X.shape[0] - количество n тензоров x \n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        \n",
    "        for j in range(r):\n",
    "            a = torch.zeros(D)\n",
    "            M = torch.norm(x) / (math.sqrt(delta * D))\n",
    "        \n",
    "            b = torch.mm(U.T, x.reshape(d, 1))\n",
    "            b_ = torch.sign(b) * torch.min(torch.abs(b), M)\n",
    "            x = x - (torch.mm(U, b_)).T\n",
    "            a = a + b_.T\n",
    "            M = eta * M\n",
    "\n",
    "        A[i] = a\n",
    "\n",
    "    return A\n",
    "\n",
    "\n",
    "def find_initial_tenzors(A, U: torch.FloatTensor):\n",
    "\n",
    "    return torch.mm(A, U.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = torch.randn(7, 10)\n",
    "\n",
    "d = tensors.shape[1]\n",
    "D = 2 * d\n",
    "lamb = find_lamb(d, D)\n",
    "\n",
    "U = find_matrix_U(d, D)\n",
    "\n",
    "delta = 0.9\n",
    "# eta = find_eta(D, U, tensors)\n",
    "eta = hardcode_eta(lamb)\n",
    "\n",
    "A = gridsearch_all_a(tensors, lamb, D, delta, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4279, -0.5669, -0.7766, -0.1700,  1.0480, -0.2874,  1.3806, -0.2000,\n",
      "          1.3603, -0.7428],\n",
      "        [-0.7056, -1.1293,  0.5785,  0.4943,  0.8402,  0.8910, -2.0942, -1.0379,\n",
      "         -0.0473, -1.7113],\n",
      "        [ 1.9014, -1.4676,  0.5668,  1.6664, -0.0883, -0.0584, -1.1967,  1.3274,\n",
      "         -0.6571,  0.0211],\n",
      "        [ 0.4607, -1.3493, -0.4328,  1.8162, -0.6149,  1.5118, -0.3878,  2.2324,\n",
      "          1.5488,  0.7672],\n",
      "        [-1.0334, -0.7379,  0.1144,  1.3409,  0.9018,  0.9193, -0.4552,  1.5643,\n",
      "          0.5804,  0.9108],\n",
      "        [-0.0184,  2.1789, -0.5542, -1.7763,  1.1840,  0.9995, -0.0973, -0.4935,\n",
      "         -1.0382,  0.7797],\n",
      "        [-0.0142, -0.4468,  0.7289, -0.0745,  0.8223, -0.0173, -0.9905,  0.2931,\n",
      "         -0.1123, -0.4882]])\n"
     ]
    }
   ],
   "source": [
    "print(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.3115e-08, -1.3389e-07,  4.7257e-08, -4.2543e-08, -4.6363e-07,\n",
      "          3.4409e-07,  3.0667e-07,  5.6985e-07,  2.6006e-07,  4.6097e-07,\n",
      "          3.2806e-07, -2.3867e-07, -1.4581e-07,  3.6486e-07,  1.8839e-07,\n",
      "         -2.6275e-07, -4.6939e-07, -8.6685e-08, -3.8949e-07, -2.5736e-07],\n",
      "        [-4.2570e-07, -3.7640e-08,  5.3613e-07,  2.8840e-07,  3.3858e-08,\n",
      "         -3.6031e-07, -4.0270e-08,  3.6227e-07,  3.8562e-07, -2.1519e-07,\n",
      "          1.2471e-07, -3.2318e-08,  3.6127e-07,  5.5914e-07,  2.6575e-07,\n",
      "         -4.1569e-08,  2.3398e-07, -2.6525e-07,  4.1276e-07,  3.3828e-07],\n",
      "        [ 1.1175e-05,  3.5788e-06, -1.6169e-05, -4.3347e-06,  3.8772e-05,\n",
      "          3.8727e-06,  3.8772e-05,  1.8761e-05, -2.4950e-05,  9.4437e-06,\n",
      "          5.1580e-06,  2.2438e-05,  2.6637e-05, -2.5304e-06,  1.1489e-05,\n",
      "          4.1491e-06, -1.7504e-06, -1.8929e-05,  7.0530e-06,  1.0579e-05],\n",
      "        [ 4.5712e-07, -3.3297e-07,  1.1649e-06, -4.9417e-07,  4.8416e-07,\n",
      "          7.6623e-07, -5.3994e-07,  9.8298e-08, -7.6999e-07,  2.6048e-07,\n",
      "         -4.5697e-07,  1.0829e-07,  9.1287e-07,  1.1231e-06, -4.6794e-07,\n",
      "          8.0860e-07,  1.7389e-07,  8.3629e-07, -1.0036e-06,  2.0569e-07],\n",
      "        [ 2.4106e-07, -1.7559e-07,  6.1431e-07, -2.6060e-07,  2.5532e-07,\n",
      "          4.0406e-07, -2.8473e-07,  5.1836e-08, -4.0605e-07,  1.3736e-07,\n",
      "         -2.4098e-07,  5.7104e-08,  4.8140e-07,  5.9228e-07, -2.4676e-07,\n",
      "          4.2641e-07,  9.1701e-08,  4.4101e-07, -5.2923e-07,  1.0847e-07],\n",
      "        [-8.8600e-06, -2.8374e-06,  1.2819e-05,  3.4367e-06, -3.0740e-05,\n",
      "         -3.0704e-06, -3.0740e-05, -1.4874e-05,  1.9781e-05, -7.4873e-06,\n",
      "         -4.0895e-06, -1.7790e-05, -2.1119e-05,  2.0062e-06, -9.1086e-06,\n",
      "         -3.2895e-06,  1.3878e-06,  1.5007e-05, -5.5919e-06, -8.3872e-06],\n",
      "        [ 2.8439e-07,  7.2341e-07, -6.9692e-07,  7.0757e-07, -1.0697e-06,\n",
      "          4.9698e-07, -2.2749e-07, -9.4046e-07, -1.2508e-06,  1.2906e-06,\n",
      "          5.8251e-07,  6.4319e-07,  6.8384e-07,  9.1144e-07,  4.3974e-07,\n",
      "         -2.7279e-06,  2.7279e-06, -6.6075e-08, -1.0194e-06,  1.7733e-07]])\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.7319e-07, -1.5987e-07, -5.9050e-08,  1.1001e-07,  8.4945e-09,\n",
       "         -3.6140e-07, -6.6839e-08,  1.8970e-07, -1.4792e-07, -3.7412e-07],\n",
       "        [-2.9404e-07,  3.6712e-07,  2.1016e-07,  5.2411e-07, -4.1370e-07,\n",
       "          1.5960e-07, -2.6191e-07, -5.5541e-07,  2.5969e-07, -4.1262e-07],\n",
       "        [ 5.8108e-06, -4.0903e-05,  9.5040e-06,  3.8832e-05,  9.6101e-07,\n",
       "         -1.8322e-05, -1.9220e-05,  1.4477e-06, -1.1697e-05,  1.1844e-05],\n",
       "        [ 3.1175e-08,  8.2461e-07, -4.1915e-07,  9.7516e-07, -5.0072e-07,\n",
       "          8.8481e-07, -4.9853e-07,  1.4819e-06,  6.6615e-07, -5.4574e-07],\n",
       "        [ 1.6440e-08,  4.3485e-07, -2.2103e-07,  5.1424e-07, -2.6405e-07,\n",
       "          4.6659e-07, -2.6290e-07,  7.8144e-07,  3.5129e-07, -2.8779e-07],\n",
       "        [-4.6070e-06,  3.2429e-05, -7.5351e-06, -3.0788e-05, -7.6192e-07,\n",
       "          1.4526e-05,  1.5238e-05, -1.1478e-06,  9.2737e-06, -9.3904e-06],\n",
       "        [-4.3234e-07,  8.0481e-07,  4.0766e-06,  1.6001e-07,  1.2993e-06,\n",
       "          1.1663e-06,  3.4016e-07,  2.3052e-07, -2.2081e-07,  5.7654e-07]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_initial_tenzors(A, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = a.reshape(D, 1) \n",
    "# eta = torch.norm(torch.matmul(U, x)) / torch.norm(x)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
